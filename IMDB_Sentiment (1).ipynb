{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1b13da-d237-4909-adfe-805428886397",
   "metadata": {},
   "source": [
    "INTRODUCTION\n",
    "\n",
    "Here, I'm using an IMDB dataset of 50K movie reviews.\n",
    "\n",
    "The dataset consists of two columns namely, reviews and sentiments which will help to identify the nature of review i.e, positive or negative. I will be using different machine learning algorithms to predict sentiment for a given movie review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd9540-dfa9-4861-a343-26d06ce3e352",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b358cd98-66b2-4470-ac4b-589df9a0e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e2400-35fa-40b7-8259-4d8ab2657329",
   "metadata": {},
   "source": [
    "PROCESSING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7716ee-b29f-46ad-8232-a7426584ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for direc, _, files in os.walk('/Users/input'):\n",
    "    for file in files:\n",
    "        print(os.path.join(direc, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98f93c4a-ad99-45af-a3d9-7b3caa559bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = pd.read_csv(r\"\\Users\\shiva\\Downloads\\arch\\IMDB Dataset.csv\")      #Importing training dataset\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dc751-b148-4da3-99dc-84702804ec58",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "SPLITTING TRAINING & TESTING SET FROM THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f631e409-9033-4b5a-9a03-f90b235287e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,test = train_test_split(Dataset, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2063425a-3434-4ddd-8b52-f57e192e6fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    16792\n",
       "positive    16708\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = train['review'], train['sentiment']\n",
    "test_x, test_y = test['review'], test['sentiment']\n",
    "\n",
    "train_y.value_counts()       #sentiment count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac8232-e20d-41ad-bfd4-264cdfc232e1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f7fc01-f200-4d4f-a9f4-46ea3f391f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380d8c6-a05c-4fdd-a8a8-636c994d8fa1",
   "metadata": {},
   "source": [
    "ELIMINATING NOISE & HTML TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f746a8-1413-4d78-9e6c-c05c3313fbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def pipe_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")                  #Removing HTML texts\n",
    "    return soup.get_text()\n",
    "\n",
    "\n",
    "def denoise_text(text):                                       #Removing noise\n",
    "    text = pipe_html(text)\n",
    "    return text\n",
    "\n",
    "Dataset['review'] = Dataset['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed2ce3-4f27-4160-887f-ce1071aaf0ba",
   "metadata": {},
   "source": [
    "BAG OF WORDS (BoW) MODEL\n",
    "\n",
    "This model is being used to extract features from raw texts in order to implement it in machine learning algorithms. These algorithms take input in the form of numerical vectors, therefore the texts are converted into vectors by counting the frequency of each word appearing; this process is termed as vectorization.\n",
    "\n",
    "I am using Term Frequency - Inverse Document Frequency (TF-IDF) algorithm for vectorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e431f0-d9fc-4538-b60d-c031104863db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "train_x_vector = tfidf.fit_transform(train_x)\n",
    "\n",
    "test_x_vector = tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20610a5-37f3-4056-b3ec-39ee1eca74e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00000000000</th>\n",
       "      <th>00000001</th>\n",
       "      <th>00001</th>\n",
       "      <th>000dm</th>\n",
       "      <th>000s</th>\n",
       "      <th>001</th>\n",
       "      <th>003830</th>\n",
       "      <th>007</th>\n",
       "      <th>...</th>\n",
       "      <th>übermenschlich</th>\n",
       "      <th>überwoman</th>\n",
       "      <th>ünel</th>\n",
       "      <th>üvegtigris</th>\n",
       "      <th>üzümcü</th>\n",
       "      <th>ýs</th>\n",
       "      <th>þorleifsson</th>\n",
       "      <th>þór</th>\n",
       "      <th>יגאל</th>\n",
       "      <th>כרמון</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38352</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33500 rows × 86049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00       000  00000000000  00000001  00001  000dm  000s  001  003830  \\\n",
       "23990  0.0  0.052519          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "8729   0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "3451   0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "2628   0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "38352  0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "...    ...       ...          ...       ...    ...    ...   ...  ...     ...   \n",
       "11284  0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "44732  0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "38158  0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "860    0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "15795  0.0  0.000000          0.0       0.0    0.0    0.0   0.0  0.0     0.0   \n",
       "\n",
       "       007  ...  übermenschlich  überwoman  ünel  üvegtigris  üzümcü   ýs  \\\n",
       "23990  0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "8729   0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "3451   0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "2628   0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "38352  0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "...    ...  ...             ...        ...   ...         ...     ...  ...   \n",
       "11284  0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "44732  0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "38158  0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "860    0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "15795  0.0  ...             0.0        0.0   0.0         0.0     0.0  0.0   \n",
       "\n",
       "       þorleifsson  þór  יגאל  כרמון  \n",
       "23990          0.0  0.0   0.0    0.0  \n",
       "8729           0.0  0.0   0.0    0.0  \n",
       "3451           0.0  0.0   0.0    0.0  \n",
       "2628           0.0  0.0   0.0    0.0  \n",
       "38352          0.0  0.0   0.0    0.0  \n",
       "...            ...  ...   ...    ...  \n",
       "11284          0.0  0.0   0.0    0.0  \n",
       "44732          0.0  0.0   0.0    0.0  \n",
       "38158          0.0  0.0   0.0    0.0  \n",
       "860            0.0  0.0   0.0    0.0  \n",
       "15795          0.0  0.0   0.0    0.0  \n",
       "\n",
       "[33500 rows x 86049 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(train_x_vector,\n",
    "                                  index=train_x.index,\n",
    "                                  columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c8c6f-6916-46b6-99b2-4982ebae5dbe",
   "metadata": {},
   "source": [
    "DETERMINING SUITABLE MACHINE LEARNING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641a1d6-3f36-4e40-9e65-4be7e6c6d46c",
   "metadata": {},
   "source": [
    "Here, I will be using supervised learning algorithms - Decision tree, logistic regression & support vector machine, since labelled data is used for both input and output. Eventually, the ML model having higher accuracy will be selected for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e94428-a700-44a0-961c-12e0e7c7e7d2",
   "metadata": {},
   "source": [
    "1. DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "242a2107-b0b7-47d7-b0e5-8479c5e00c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Dtree = DecisionTreeClassifier()\n",
    "Dtree.fit(train_x_vector, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c99cf-c047-4d03-8364-9729558954e6",
   "metadata": {},
   "source": [
    "2. LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb406fb6-c8d3-43f8-b18a-48367cd4876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(train_x_vector,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af4195e0-e825-46a8-aa56-febd6d4af82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "Logr = LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "\n",
    "Logr_tfidf = Logr.fit(train_x_vector,train_y)\n",
    "print(Logr_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c0d3d-31ec-4319-b7ad-aba99d5103ba",
   "metadata": {},
   "source": [
    "3. SUPPORT VECTOR MACHINE (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59f3d9c-b1b9-4c92-9a25-f92d3c718c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['positive']\n",
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM.fit(train_x_vector, train_y)\n",
    "\n",
    "\n",
    "print(SVM.predict(tfidf.transform(['A good movie'])))\n",
    "print(SVM.predict(tfidf.transform(['An excellent movie'])))\n",
    "print(SVM.predict(tfidf.transform(['I did not like this movie at all I gave this movie away'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3908a88-c499-4860-8f0f-5d15ecc40292",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331bd3b-7f5a-4b22-a14f-49f76441a13d",
   "metadata": {},
   "source": [
    "ASSESSMENT OF MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd24e14-eb7b-491a-a00f-b5ba186e4941",
   "metadata": {},
   "source": [
    "1. AVERAGE ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5160bbd-826d-4847-903b-c37aa208e1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7246666666666667\n",
      "0.8918181818181818\n",
      "0.8938787878787878\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(Dtree.score(test_x_vector, test_y))\n",
    "\n",
    "print(LogReg.score(test_x_vector, test_y))\n",
    "\n",
    "print(SVM.score(test_x_vector, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf23d2c-0f02-4cee-9580-6115387fcb6c",
   "metadata": {},
   "source": [
    "As per the above results, the support vector machine algorithm generated output with maximum accuracy. Therefore, I will be taking this model into consideration for further assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b34e4-1865-47ce-9446-5b889271ea9e",
   "metadata": {},
   "source": [
    "2. F1 SCORE\n",
    "\n",
    "It evaluates the predictive skill of this model by elaborating on its class-wise performance, measuring the frequency of correct predictions made throughout the whole class-balanced dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6789e2b9-e580-4a7d-ba4e-d4fe33c9a208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89553129, 0.89217316])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_y,SVM.predict(test_x_vector),\n",
    "          labels = ['positive','negative'],average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b9961-8cc4-4b3f-93ca-1abc4f0164a7",
   "metadata": {},
   "source": [
    "3. CLASSIFICATION REPORT\n",
    "\n",
    "Report summarizing the performance evaluation metrics of support vector machine model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad392711-872a-435b-9a2f-b84fac609912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.89      0.91      0.90      8292\n",
      "    negative       0.90      0.88      0.89      8208\n",
      "\n",
      "    accuracy                           0.89     16500\n",
      "   macro avg       0.89      0.89      0.89     16500\n",
      "weighted avg       0.89      0.89      0.89     16500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_y,\n",
    "                            SVM.predict(test_x_vector),\n",
    "                            labels = ['positive','negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b395b9-ad60-45ea-bdfa-ffa28e5d9005",
   "metadata": {},
   "source": [
    "4. CONFUSION MATRIX\n",
    "\n",
    "The confusion matrix is a representation of performance evaluation of this classification model - SVM. It compares the actual output values with those predicted by the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "655173ac-608a-4505-8eeb-1408973bad29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7505,  787],\n",
       "       [ 964, 7244]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "con_matrix = confusion_matrix(test_y,\n",
    "                           SVM.predict(test_x_vector),\n",
    "                           labels = ['positive', 'negative'])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0245e7-85d1-461e-b42e-c929ecb07b52",
   "metadata": {},
   "source": [
    "INFERENCE\n",
    "\n",
    "\n",
    "My overall analysis shows that support vector machine algorithm has higher accuracy as compared to other supervised learning models that have been tested to obtain desired output.\n",
    "The accuracy of the model can be revamped by -\n",
    "\n",
    "~ Refined data pre-processing\n",
    "\n",
    "~ Avoiding data loss during vectorization and converting back to scalar form\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
